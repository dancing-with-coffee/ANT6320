{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
    "\n",
    "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/user/.fastai/data/imdb_sample/texts.csv'),\n",
       " PosixPath('/home/user/.fastai/data/imdb_sample/data_save.pkl')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE) # IMDB 데이터셋을 불러옵니다. 50000개중에 25000/25000이 postive/negative로 되어있다.\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only contains one csv file, let's have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv') # 데이터는 아래와 같이, label / text / is_valid column으로 이루어져있다. is_valid column은 각 row가 validation set으로 쓸것인지 아닌지를 결정해준다.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is some merit in this view, but it\\'s also true that no one forced Hindus and Muslims in the region to mistreat each other as they did around the time of partition. It seems more likely that the British simply saw the tensions between the religions and were clever enough to exploit them to their own ends.<br /><br />The result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen. But it is never painted as a black-and-white case. There is baseness and nobility on both sides, and also the hope for change in the younger generation.<br /><br />There is redemption of a sort, in the end, when Puro has to make a hard choice between a man who has ruined her life, but also truly loved her, and her family which has disowned her, then later come looking for her. But by that point, she has no option that is without great pain for her.<br /><br />This film carries the message that both Muslims and Hindus have their grave faults, and also that both can be dignified and caring people. The reality of partition makes that realisation all the more wrenching, since there can never be real reconciliation across the India/Pakistan border. In that sense, it is similar to \"Mr & Mrs Iyer\".<br /><br />In the end, we were glad to have seen the film, even though the resolution was heartbreaking. If the UK and US could deal with their own histories of racism with this kind of frankness, they would certainly be better off.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1] # 두번째 데이터의 text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextDataBunch.from_csv(path, 'texts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A `TextDataBunch` does all of that behind the scenes for you.\n",
    "\n",
    "Before we delve into the explanations, let's take the time to save the things that were calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time we launch this notebook, we can skip the cell above that took a bit of time (and that will take a lot more when you get to the full dataset) and load those results like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of processing we make the texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n",
    "\n",
    "- we need to take care of punctuation\n",
    "- some words are contractions of two different words, like isn't or don't\n",
    "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
    "\n",
    "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the sweetest and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj sydney , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n \\n  xxmaj it 's usually satisfying to watch a film director change his style /</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this film sat on my xxmaj tivo for weeks before i watched it . i dreaded a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the screwed - up xxunk of xxmaj new xxmaj xxunk . \\n \\n  xxmaj the format is the same as xxmaj max xxmaj xxunk ' \" xxmaj la xxmaj ronde</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i really wanted to love this show . i truly , honestly did . \\n \\n  xxmaj for the first time , gay viewers get their own version of the \" xxmaj the xxmaj bachelor \" . xxmaj with the help of his obligatory \" hag \" xxmaj xxunk , xxmaj james , a good looking , well - to - do thirty - something has the chance</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj to review this movie , i without any doubt would have to quote that memorable scene in xxmaj tarantino 's \" xxmaj pulp xxmaj fiction \" ( xxunk ) when xxmaj jules and xxmaj vincent are talking about xxmaj mia xxmaj wallace and what she does for a living . xxmaj jules tells xxmaj vincent that the \" xxmaj only thing she did worthwhile was pilot \" .</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = TextClasDataBunch.from_csv(path, 'texts.csv') # csv에서 데이터를 가져온다.\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n",
    "- the \"'s\" are grouped together in one token\n",
    "- the contractions are separated like this: \"did\", \"n't\"\n",
    "- content has been cleaned for any HTML symbol and lower cased\n",
    "- there are several special tokens (all those that begin by xx), to replace unknown tokens (see below) or to introduce different text fields (here we only have one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at least twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
    "\n",
    "The correspondance from ids to tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.itos[:10] # data.vocab에는 모든 단어의 Index가 있고, 그것을 itos Method를 통해 바꾸면 각 단어에 해당하는 index를 해당 단어로 바꿔준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj awesomely improbable and foolish xxunk that at least has some redeeming , crisp location photography , but it 's too unbelievable to generate much in the way of tension . i was kinda hoping that xxmaj stanwyck would n't make it back in time because , really , she was xxunk with the wet , in more ways than one , husband , and she had an idiot child as well .. why xxup not run off with xxmaj xxunk ? xxmaj but the xxunk question remains .. what sort of wood was that pier support made of if a xxunk piece of it pulled off did n't xxunk ? xxmaj stanwyck , always impeccably professional , does the best she could with the material but it 's xxunk ."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the underlying data is all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5, 6071, 2195,   12, 3790,    0,   21,   47,  225])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the data block API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the data block API with NLP and have a lot more flexibility than what the default factory methods offer. In the previous example for instance, the data was randomly split between train and validation instead of reading the third column of the csv.\n",
    "\n",
    "With the data block API though, we have to manually call the tokenize and numericalize steps. This allows more flexibility, and if you're not using the defaults from fastai, the various arguments to pass will appear in the step they're revelant, so it'll be more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                .split_from_df(col=2)\n",
    "                .label_from_df(cols=0)\n",
    "                .databunch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=48 #batch_size = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab the full dataset for what follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/user/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/unsup'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/data_clas.pkl'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/data_lm.pkl'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/models')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/user/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/train/neg'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/user/.fastai/data/imdb/train/pos')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder on top of `train` and `test` that contains the unlabelled data.\n",
    "\n",
    "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipedia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word is, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
    "\n",
    "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviews left by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust the parameters of our model by a little bit. Plus there might be some words that would be extremely common in the reviews dataset but would be barely present in wikipedia, and therefore might not be part of the vocabulary the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = (TextList.from_folder(path)\n",
    "           #Inputs: all the text files in path\n",
    "            .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
    "            .split_by_rand_pct(0.1)\n",
    "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "            .label_for_lm()           \n",
    "           #We want to do a language model so we label accordingly\n",
    "            .databunch(bs=bs))\n",
    "data_lm.save('data_lm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
    "\n",
    "The line before being a bit long, we want to load quickly the final ids by using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path, 'data_lm.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>movie plot , so just plan to enjoy the action , and do not expect a coherent plot . xxmaj turn any sense of logic you may have , it will reduce your chance of getting a headache . \\n \\n  i does give me some hope that xxmaj steven xxmaj seagal is trying to move back towards the type of characters he portrayed in his more popular movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>that causes him to go boss - eyed . xxmaj probably hilarious if you 're stoned , but to a child , quite disturbing . xxmaj speaking of which , the infamous ' hippo cull ' scene is represented in an abstract manner - clouds in vague hippo shapes are struck by lightning - but it 's still pretty unpleasant . xxmaj in fact , this film is pretty cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>, and a loud computerized voice echoes and flashes \" xxmaj fight xxmaj mode \" . xxmaj that must be a dandy design if you are trying to sneak up on somebody . xxmaj then you go to a big power station which looks just like a current day power line tower and plug in to charge back up . xxup lol , i 'm not kidding , you ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dolph xxmaj lundgren 's xxmaj punisher ( also a comic adaptation , perhaps there is a trend here ? ) . xxmaj surely the audience is meant to be on the same side as the ' hero ' ? xxmaj and whilst a vampire can be a tragic character , this is not true of xxmaj blade , he is relentlessly cruel , scornful and not a whole lot better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the film moves that everything is not what it seems , yet i feel the movie fails at giving you enough to go on to truly care afterward . xxmaj it 's about perception . xxmaj there are characters the heroine xxunk xxmaj xxunk in the film that she talks to that up and vanish . xxmaj this might seem like a spoiler , but it 's something that really</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWD_LSTM은 LSTM을 사용해서 Language Model을 만들기 위해 sgd optimizer를 변형한 NT-ASGD를 사용하며, Dropconnect를 LSTM에 적용하여 학습이 잘되도록 한다.\n",
    "# Reference : https://arxiv.org/abs/1708.02182\n",
    "# AWD_LSTM 대신에 Transformer, TransformerXL도 사용할 수 있다.\n",
    "# drop_mult는 dropout의 rate를 결정한다.\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='99' class='' max='8052', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.23% [99/8052 00:12<16:10 11.5695]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.165946</td>\n",
       "      <td>4.026157</td>\n",
       "      <td>0.294885</td>\n",
       "      <td>17:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# moms는 cyclical momentum값. (0.8과 0.7) 사이에서 momentum에 사용할 optimal phi값을 찾는다.\n",
    "# Reference : https://arxiv.org/pdf/1803.09820.pdf\n",
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the fine-tuning, we can then unfeeze and launch a new training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.869107</td>\n",
       "      <td>3.846509</td>\n",
       "      <td>0.312888</td>\n",
       "      <td>17:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.839792</td>\n",
       "      <td>3.805870</td>\n",
       "      <td>0.319777</td>\n",
       "      <td>17:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.803273</td>\n",
       "      <td>3.780046</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>17:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.747533</td>\n",
       "      <td>3.749584</td>\n",
       "      <td>0.327028</td>\n",
       "      <td>17:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.704262</td>\n",
       "      <td>3.721799</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>17:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.664324</td>\n",
       "      <td>3.700976</td>\n",
       "      <td>0.332678</td>\n",
       "      <td>17:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.613920</td>\n",
       "      <td>3.684423</td>\n",
       "      <td>0.334670</td>\n",
       "      <td>17:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.593322</td>\n",
       "      <td>3.674699</td>\n",
       "      <td>0.336212</td>\n",
       "      <td>17:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.544340</td>\n",
       "      <td>3.669938</td>\n",
       "      <td>0.336932</td>\n",
       "      <td>17:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.498464</td>\n",
       "      <td>3.669881</td>\n",
       "      <td>0.337023</td>\n",
       "      <td>17:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7)) # 10 epoch, lr=0.0001, momentum range = (0.8, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is our model? Well let's try to see what it predicts after a few given words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"I liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I liked this movie because it was so good . There was not much to this movie . The plot was great , the acting was way better than your average Hollywood movie . It was very realistic . It\n",
      "I liked this movie because it was a good movie . It was a solid thriller , though definitely not very convincing . The acting was okay as well as the direction . The cinematography was also great . The acting\n"
     ]
    }
   ],
   "source": [
    "# TEXT 이하에 나오는 40단어를 가지는 문장 2개를 학습된 LM을 통해서 생성한다. AWD_LSTM에 TEXT를 inference한 결과다.\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to save not only the model, but also its encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB) # 이번에 IMDB를 통해 pos/neg를 판단하는 classification을 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))\n",
    "\n",
    "data_clas.save('data_clas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = load_data(path, 'data_clas.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj titanic directed by xxmaj james xxmaj cameron presents a fictional love story on the historical setting of the xxmaj titanic . xxmaj the plot is simple , xxunk , or not for those who love plots that twist and turn and keep you in suspense . xxmaj the end of the movie can be figured out within minutes of the start of the film , but the love</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxunk ) is the developing world 's answer to xxmaj silence of the xxmaj lambs . xxmaj where ` xxmaj silence ' terrorized our peace of mind , ` xxmaj citizen ' xxunk and saddens us instead . xxmaj this dramatization of the xxmaj chikatilo case translates rather well , thanks to a xxmaj westernized friendship between two xxmaj rostov cops who become equals . \\n \\n  citizenx</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj on xxmaj sunday xxmaj july 27 , 1997 , the first episode of a new science fiction series called \" xxmaj stargate xxup sg-1 \" was broadcast on xxmaj showtime . a spin - off of and sequel to the 1994 film \" xxmaj stargate \" starring xxmaj kurt xxmaj russell and xxmaj james xxmaj spader , the series begins approximately one year after the events portrayed in</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this film sat on my xxmaj tivo for weeks before i watched it . i dreaded a self - indulgent yuppie flick about relationships gone bad . i was wrong ; this was an engrossing excursion into the screwed - up libidos of xxmaj new xxmaj yorkers . \\n \\n  xxmaj the format is the same as xxmaj max xxmaj ophuls ' \" xxmaj la xxmaj ronde</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a model to classify those reviews and load the encoder we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxup star xxup rating : xxrep 5 * xxmaj saturday xxmaj night xxrep 4 * xxmaj friday xxmaj night * * * xxmaj friday xxmaj morning * * xxmaj sunday xxmaj night * xxmaj monday xxmaj morning \n",
       " \n",
       "  xxmaj james xxmaj dial ( xxmaj wesley xxmaj snipes ) is hiding out on his ranch in xxmaj montana after failing to capture a notorious terrorist . xxmaj then he 's approached by the agency again to travel to xxmaj london to have another go . xxmaj his target has been apprehended there and is under heavy police xxunk but they do n't want him merely to capture their man- they want him taken out . xxmaj all goes well but then the mission gets botched and when a senior police chief , xxmaj windsor ( xxmaj charles xxmaj dance ) is killed , the blame falls at xxmaj dial 's feet . xxmaj hunted like an animal , he takes refuge in a nearby house and befriends a young girl named xxmaj emily ( xxmaj eliza xxmaj bennett ) who 's dealing with issues of her own and becomes his unwitting sidekick as he goes about clearing his name and working out who betrayed him . \n",
       " \n",
       "  xxmaj this latest xxmaj snipes straight to xxup dvd escapade came out of nowhere , with a minimal of publicity even for something so small time ( i do n't recall seeing any advertisements or trailers for it anywhere . ) xxmaj with this in mind and after xxmaj snipes 's history of duff xxup dvd efforts , this might have seemed like one which xxmaj snoop xxmaj dawg would tell you to drop like it 's hot . xxmaj but i felt compelled to give it a go anyway . xxmaj it does n't rank among his worst , but it does n't reach any higher than the standards of some of his better ones ( xxmaj the xxmaj detonator , 7 xxmaj seconds , says it all , really ) , either . \n",
       " \n",
       "  xxmaj this is , at best , mildly suspenseful , with a minimal of action , naff all in the way of cool dialogue and xxmaj snipes not exactly at his best in the lead role . xxmaj likewise , in a main supporting role , it 's quite clear xxmaj dance has only showed up for the pay cheque as well and this is generally one that none of the cast are going to shout for the hills about on any of their cvs . \n",
       " \n",
       "  xxmaj it says a lot that by the end the only ' contract ' that 's keeping you interested is when xxmaj snipes 's will end with xxmaj sony and with it an end to any further sub par xxup el xxup dvd action films . * *,xxbos xxmaj the plot was predictable , and fighting with guns gets old , but this is a definate movie to look at if you have a low xxup iq and do n't really care about real movies . i would xxunk in true art movies , like ' xxmaj clerks ' , ' xxmaj something about xxmaj mary ' , ' xxmaj el xxmaj mariachi ' , or ' xxmaj la xxmaj xxunk ' .,xxbos i can not believe the same guy directed this crap and xxmaj dracula 2000 . xxmaj dracula 2000 was innovative , fresh , and well written , if poorly acted . \n",
       " \n",
       "  xxmaj this pile ca n't even claim that . xxmaj it starts with the defeat of xxmaj dracula at the end of xxmaj dracula 2000 . xxmaj then ignores the narrative afterwards describing what happened after that . xxmaj following the narrative properly could have made this a good sequel somehow , but xxmaj craven chose to go in the style of his older films , having no good tie but the main villain 's name . \n",
       " \n",
       "  xxmaj even the actor playing xxmaj dracula was different ( going from dark hair in xxmaj dracula 2000 to a blonde here ) . \n",
       " \n",
       "  xxmaj avoid this movie if you have any respect for your taste in movies .,xxbos xxmaj now do n't get me wrong . xxmaj if you need an insightful summary of everything that been wrong with the history of human civilization as well as a flawless path to brighter future for mankind , who better to turn to than a comedian and practitioner of pop culture ? xxmaj if you need a healthy dose of all the solid , sound reasons why religion has outlived it 's usefulness then turn to xxmaj sagan or xxmaj dawkins , not xxup bill xxup maher for xxmaj god 's ( ? ) sake ! xxmaj that 's a good point in and of itself . xxmaj maher dismisses our religious past as a neurological disorder conveniently ignoring how his entire society , art and science is rooted in it . \n",
       " \n",
       "  xxmaj in this film , he relies heavily on his keenly - honed skill set of irony and cynicism to make his point while attempting to appear erudite and wise . xxmaj unfortunately , his intellect is n't up to the task . \n",
       " \n",
       "  xxmaj maher makes us laugh but is clearly not the brightest bulb in the box . xxmaj as an example , he responds to an interviewee 's ( and i use the term loosely as they were clearly all \" xxunk \" ) assertion that the existence of xxmaj jesus is historical fact with a deadpan \" xxmaj no , it 's not \" followed by a long stare meant to convey contempt at the subject 's naivety ( a device nauseatingly overused in this film ) . xxmaj the problem is that the person was correct and xxmaj maher dead wrong in his assertion that xxmaj jesus is mentioned only in what he considers to be the xxunk suspect gospels . i guess xxmaj mr. xxmaj maher has never read the contemporary historian xxmaj xxunk . \n",
       " \n",
       "  xxmaj but the masses will flock to this pseudo - documentary as they do the fictional works of other intellectual giants like xxmaj michael xxmaj moore , and they will loudly bray and guffaw ( they certainly did at my showing ) . \n",
       " \n",
       "  xxmaj it 's doubly telling , however , that the loudest and most mule - like braying occurred during the approximately 70 % of the running time that the film devoted to it 's anti - xxmaj christian tirade while the audience was wholly mute during the token 10 % devoted to criticizing the self - described xxmaj religion of xxmaj peace . xxmaj hmmm . xxmaj either criticism of xxmaj islam is off - limits to the hip and liberal target audience or they were just afraid to laugh . xxmaj very telling , either way ..,xxbos xxmaj repetitive music , annoying narration , terrible cinematography effects . xxmaj half of the plot seemed centered around shock value and the other half seemed to be focused on appeasing the type of crowd that would nag at people to start a fight . \n",
       " \n",
       "  xxmaj one of the best scenes was in the \" deleted scenes \" section , the one where she 's in the principle 's office with her mom . i do n't understand why they 'd cut that . xxmaj the movie seemed desperate to make a point about anything it could and xxmaj domino talking about sororities would have been a highlight of the movie . \n",
       " \n",
       "  xxmaj ridiculous camera work is reminiscent of xxup mtv , and completely not needed or helpful to a movie . xxmaj speeding the film up just to jump past a lot of things and rotating the camera around something repeatedly got old the first time it was used . xxmaj it 's like the directors are wanting to use up all this extra footage they did n't want to throw away . \n",
       " \n",
       "  xxmaj another movie with xxmaj jerry xxmaj springer in it ? xxmaj that should 've told me not to watch it from the preview . \n",
       " \n",
       "  a popular movie for the \" in \" crowd .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: /home/user/.fastai/data/imdb;\n",
       "\n",
       "Valid: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos * * * xxup mild xxup spoilers * * * xxmaj dear xxmaj inman , xxmaj kind words are hard to find for me to describe the movie i have just been subjected to that stars you . xxmaj the problems are far and wide and painful for me to recount . . . yet i feel i must , if only to prevent others from suffering the same anguish as i did . xxmaj this is xxup not a film for anyone under 50 , it 's sl xxrep 4 o xxrep 5 w , s xxrep 6 o slo xxrep 4 w , and when the big reunion of xxmaj ada and xxmaj inman happens . . .the biggest and most important scene in the film , xxup nothing happens , it is a epic letdown . xxmaj now , like the director should have done , i will keep my words short and end with this warning , your film is disjointed , boring , has no flow and xxmaj jude xxmaj law is tragically mis - cast , he showed more emotion as a robot in xxup a.i. - be warned , the film should be retitled . . . xxmaj bored xxmaj mountain . xxmaj love , xxmaj ada,xxbos xxmaj the film quickly gets to a major chase scene with ever increasing destruction . xxmaj the first really bad thing is the guy hijacking xxmaj steven xxmaj seagal would have been beaten to pulp by xxmaj seagal 's driving , but that probably would have ended the whole premise for the movie . \n",
       " \n",
       "  xxmaj it seems like they decided to make all kinds of changes in the movie plot , so just plan to enjoy the action , and do not expect a coherent plot . xxmaj turn any sense of logic you may have , it will reduce your chance of getting a headache . \n",
       " \n",
       "  i does give me some hope that xxmaj steven xxmaj seagal is trying to move back towards the type of characters he portrayed in his more popular movies .,xxbos i saw that this movie was coming out and could not wait to see it . i have to say i was very disappointed with it . xxmaj this would have been better as a mini - series . xxmaj the whole show seemed very rushed . xxmaj they did not explain things very clearly . xxmaj at the end they showed xxmaj john xxmaj paul xxup ii , alive and well and the next scene he was dead . xxmaj never any explanation as to what happened . ( xxmaj we all know what happened in real life ) i think xxup abc dropped the ball big time on something that could have been great . xxmaj in all i think this movie was a blur . xxmaj it seemed like a drunken monkey jumping around from one point in xxmaj john xxmaj paul 's life to another point never explaining how or why things happened . xxmaj such as when his older brother leaves , it was never explained that his brother was a doctor and that is why he left home . xxmaj also when his father dies , all we see is his father lying on the floor and that was that . i was very disappointed with the over all movie .,xxbos xxmaj one would think that with all the lavish care and expense that went into this made - for - xxup tv movie , it would reflect something of the taste and manners of the upper class couple -- xxmaj wallis xxmaj simpson and the xxmaj prince of xxmaj wales -- instead of being a mawkish , unappetizing historical romance . \n",
       " \n",
       "  xxmaj nor is it helped by the fact that xxup jane xxup seymour and xxup anthony xxup andrews give stiff , rather uncomfortable to watch performances in which the events move much too slowly to hold attention . \n",
       " \n",
       "  xxmaj it 's hard to understand why a star of xxup olivia xxup de xxup havilland 's caliber would wish to play the supporting role of xxmaj aunt xxmaj bessie since the role is so colorless she just about fades out of sight . xxmaj at this stage in her career , xxmaj olivia was appearing in so many \" nobility \" roles requiring a regal presence but nothing more . \n",
       " \n",
       "  a trivial movie best left forgotten among all the made - for - xxup tv movies of that era .,xxbos xxmaj deep xxmaj sea xxup 3d is a stunning insight in to an underwater world only a few have had the opportunity to view first hand . \n",
       " \n",
       "  xxmaj from the opening sequence when a wave rushes towards the audience momentarily engulfing us in the ocean , the filmmakers make full use of the xxup imax format . a jelly fish field appears to fill the whole theatre , a shark powers towards us , predators pounce from behind rocks and devour their prey . xxmaj it is a beautifully captured under sea feast for the eyes . \n",
       " \n",
       "  xxmaj our ears on the other hand , are not given the same treatment . xxmaj the film is narrated by xxmaj hollywood stars xxmaj jonny xxmaj depp and xxmaj kate xxmaj winslet . xxmaj both sound so ridiculous it positively spoils the enjoyment of the visuals . xxmaj depp sounds slightly bored whilst xxmaj winslet sounds as if she is reading a bedtime story to the village idiot . i was shocked that an actress of her status could have pitched her performance so wrongly . xxmaj the script is fairly silly and contains very little depth . xxmaj the soundtrack is filled with strange , unrealistic sound effects which i assume are meant to be funny but in fact detract attention from the material which should have been allowed to speak for itself . \n",
       " \n",
       "  xxmaj danny xxmaj elfman has provided an excellent score which gives plenty of impact to the ups and downs of life under the sea , when it is allowed to play out without the silly bubble sounds or xxunk xxunk which pepper film . \n",
       " \n",
       "  xxmaj the film is a technical marvel but with it 's childish script , annoying narration and misplaced sound effects it can not be taken seriously .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: /home/user/.fastai/data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fd1c054c680>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/user/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이번엔 Language Model Learner가 아닌 classifier Learner를 불러온다. fastai가 제공하는 NLP learner들은 Learner class에서 init model을 할때 불러오는 learner의 이름에 따라 다른 세팅으로 모델을 불러온다.\n",
    "# 요새 NLP의 트렌드는 pretrained model을 불러와서 해당 downstream task에 fine-tuning해서 사용하는 방식이다. 아까 만든 LM을 불러와서 classifier를 만들어보자.\n",
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc') # 아까 위에서 만든 LM을 불러온다. # pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='94' class='' max='520', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      18.08% [94/520 00:26<01:59 1.9913]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.236023</td>\n",
       "      <td>0.243361</td>\n",
       "      <td>0.909560</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
    "learn.fit_one_cycle(1, 2e-2, moms=(0.99, 0.9)) # hyperparamter를 조금 바꿔보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('first')\n",
    "learn.save('first_edit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxup star xxup rating : xxrep 5 * xxmaj saturday xxmaj night xxrep 4 * xxmaj friday xxmaj night * * * xxmaj friday xxmaj morning * * xxmaj sunday xxmaj night * xxmaj monday xxmaj morning \n",
       " \n",
       "  xxmaj james xxmaj dial ( xxmaj wesley xxmaj snipes ) is hiding out on his ranch in xxmaj montana after failing to capture a notorious terrorist . xxmaj then he 's approached by the agency again to travel to xxmaj london to have another go . xxmaj his target has been apprehended there and is under heavy police xxunk but they do n't want him merely to capture their man- they want him taken out . xxmaj all goes well but then the mission gets botched and when a senior police chief , xxmaj windsor ( xxmaj charles xxmaj dance ) is killed , the blame falls at xxmaj dial 's feet . xxmaj hunted like an animal , he takes refuge in a nearby house and befriends a young girl named xxmaj emily ( xxmaj eliza xxmaj bennett ) who 's dealing with issues of her own and becomes his unwitting sidekick as he goes about clearing his name and working out who betrayed him . \n",
       " \n",
       "  xxmaj this latest xxmaj snipes straight to xxup dvd escapade came out of nowhere , with a minimal of publicity even for something so small time ( i do n't recall seeing any advertisements or trailers for it anywhere . ) xxmaj with this in mind and after xxmaj snipes 's history of duff xxup dvd efforts , this might have seemed like one which xxmaj snoop xxmaj dawg would tell you to drop like it 's hot . xxmaj but i felt compelled to give it a go anyway . xxmaj it does n't rank among his worst , but it does n't reach any higher than the standards of some of his better ones ( xxmaj the xxmaj detonator , 7 xxmaj seconds , says it all , really ) , either . \n",
       " \n",
       "  xxmaj this is , at best , mildly suspenseful , with a minimal of action , naff all in the way of cool dialogue and xxmaj snipes not exactly at his best in the lead role . xxmaj likewise , in a main supporting role , it 's quite clear xxmaj dance has only showed up for the pay cheque as well and this is generally one that none of the cast are going to shout for the hills about on any of their cvs . \n",
       " \n",
       "  xxmaj it says a lot that by the end the only ' contract ' that 's keeping you interested is when xxmaj snipes 's will end with xxmaj sony and with it an end to any further sub par xxup el xxup dvd action films . * *,xxbos xxmaj the plot was predictable , and fighting with guns gets old , but this is a definate movie to look at if you have a low xxup iq and do n't really care about real movies . i would xxunk in true art movies , like ' xxmaj clerks ' , ' xxmaj something about xxmaj mary ' , ' xxmaj el xxmaj mariachi ' , or ' xxmaj la xxmaj xxunk ' .,xxbos i can not believe the same guy directed this crap and xxmaj dracula 2000 . xxmaj dracula 2000 was innovative , fresh , and well written , if poorly acted . \n",
       " \n",
       "  xxmaj this pile ca n't even claim that . xxmaj it starts with the defeat of xxmaj dracula at the end of xxmaj dracula 2000 . xxmaj then ignores the narrative afterwards describing what happened after that . xxmaj following the narrative properly could have made this a good sequel somehow , but xxmaj craven chose to go in the style of his older films , having no good tie but the main villain 's name . \n",
       " \n",
       "  xxmaj even the actor playing xxmaj dracula was different ( going from dark hair in xxmaj dracula 2000 to a blonde here ) . \n",
       " \n",
       "  xxmaj avoid this movie if you have any respect for your taste in movies .,xxbos xxmaj now do n't get me wrong . xxmaj if you need an insightful summary of everything that been wrong with the history of human civilization as well as a flawless path to brighter future for mankind , who better to turn to than a comedian and practitioner of pop culture ? xxmaj if you need a healthy dose of all the solid , sound reasons why religion has outlived it 's usefulness then turn to xxmaj sagan or xxmaj dawkins , not xxup bill xxup maher for xxmaj god 's ( ? ) sake ! xxmaj that 's a good point in and of itself . xxmaj maher dismisses our religious past as a neurological disorder conveniently ignoring how his entire society , art and science is rooted in it . \n",
       " \n",
       "  xxmaj in this film , he relies heavily on his keenly - honed skill set of irony and cynicism to make his point while attempting to appear erudite and wise . xxmaj unfortunately , his intellect is n't up to the task . \n",
       " \n",
       "  xxmaj maher makes us laugh but is clearly not the brightest bulb in the box . xxmaj as an example , he responds to an interviewee 's ( and i use the term loosely as they were clearly all \" xxunk \" ) assertion that the existence of xxmaj jesus is historical fact with a deadpan \" xxmaj no , it 's not \" followed by a long stare meant to convey contempt at the subject 's naivety ( a device nauseatingly overused in this film ) . xxmaj the problem is that the person was correct and xxmaj maher dead wrong in his assertion that xxmaj jesus is mentioned only in what he considers to be the xxunk suspect gospels . i guess xxmaj mr. xxmaj maher has never read the contemporary historian xxmaj xxunk . \n",
       " \n",
       "  xxmaj but the masses will flock to this pseudo - documentary as they do the fictional works of other intellectual giants like xxmaj michael xxmaj moore , and they will loudly bray and guffaw ( they certainly did at my showing ) . \n",
       " \n",
       "  xxmaj it 's doubly telling , however , that the loudest and most mule - like braying occurred during the approximately 70 % of the running time that the film devoted to it 's anti - xxmaj christian tirade while the audience was wholly mute during the token 10 % devoted to criticizing the self - described xxmaj religion of xxmaj peace . xxmaj hmmm . xxmaj either criticism of xxmaj islam is off - limits to the hip and liberal target audience or they were just afraid to laugh . xxmaj very telling , either way ..,xxbos xxmaj repetitive music , annoying narration , terrible cinematography effects . xxmaj half of the plot seemed centered around shock value and the other half seemed to be focused on appeasing the type of crowd that would nag at people to start a fight . \n",
       " \n",
       "  xxmaj one of the best scenes was in the \" deleted scenes \" section , the one where she 's in the principle 's office with her mom . i do n't understand why they 'd cut that . xxmaj the movie seemed desperate to make a point about anything it could and xxmaj domino talking about sororities would have been a highlight of the movie . \n",
       " \n",
       "  xxmaj ridiculous camera work is reminiscent of xxup mtv , and completely not needed or helpful to a movie . xxmaj speeding the film up just to jump past a lot of things and rotating the camera around something repeatedly got old the first time it was used . xxmaj it 's like the directors are wanting to use up all this extra footage they did n't want to throw away . \n",
       " \n",
       "  xxmaj another movie with xxmaj jerry xxmaj springer in it ? xxmaj that should 've told me not to watch it from the preview . \n",
       " \n",
       "  a popular movie for the \" in \" crowd .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: /home/user/.fastai/data/imdb;\n",
       "\n",
       "Valid: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos * * * xxup mild xxup spoilers * * * xxmaj dear xxmaj inman , xxmaj kind words are hard to find for me to describe the movie i have just been subjected to that stars you . xxmaj the problems are far and wide and painful for me to recount . . . yet i feel i must , if only to prevent others from suffering the same anguish as i did . xxmaj this is xxup not a film for anyone under 50 , it 's sl xxrep 4 o xxrep 5 w , s xxrep 6 o slo xxrep 4 w , and when the big reunion of xxmaj ada and xxmaj inman happens . . .the biggest and most important scene in the film , xxup nothing happens , it is a epic letdown . xxmaj now , like the director should have done , i will keep my words short and end with this warning , your film is disjointed , boring , has no flow and xxmaj jude xxmaj law is tragically mis - cast , he showed more emotion as a robot in xxup a.i. - be warned , the film should be retitled . . . xxmaj bored xxmaj mountain . xxmaj love , xxmaj ada,xxbos xxmaj the film quickly gets to a major chase scene with ever increasing destruction . xxmaj the first really bad thing is the guy hijacking xxmaj steven xxmaj seagal would have been beaten to pulp by xxmaj seagal 's driving , but that probably would have ended the whole premise for the movie . \n",
       " \n",
       "  xxmaj it seems like they decided to make all kinds of changes in the movie plot , so just plan to enjoy the action , and do not expect a coherent plot . xxmaj turn any sense of logic you may have , it will reduce your chance of getting a headache . \n",
       " \n",
       "  i does give me some hope that xxmaj steven xxmaj seagal is trying to move back towards the type of characters he portrayed in his more popular movies .,xxbos i saw that this movie was coming out and could not wait to see it . i have to say i was very disappointed with it . xxmaj this would have been better as a mini - series . xxmaj the whole show seemed very rushed . xxmaj they did not explain things very clearly . xxmaj at the end they showed xxmaj john xxmaj paul xxup ii , alive and well and the next scene he was dead . xxmaj never any explanation as to what happened . ( xxmaj we all know what happened in real life ) i think xxup abc dropped the ball big time on something that could have been great . xxmaj in all i think this movie was a blur . xxmaj it seemed like a drunken monkey jumping around from one point in xxmaj john xxmaj paul 's life to another point never explaining how or why things happened . xxmaj such as when his older brother leaves , it was never explained that his brother was a doctor and that is why he left home . xxmaj also when his father dies , all we see is his father lying on the floor and that was that . i was very disappointed with the over all movie .,xxbos xxmaj one would think that with all the lavish care and expense that went into this made - for - xxup tv movie , it would reflect something of the taste and manners of the upper class couple -- xxmaj wallis xxmaj simpson and the xxmaj prince of xxmaj wales -- instead of being a mawkish , unappetizing historical romance . \n",
       " \n",
       "  xxmaj nor is it helped by the fact that xxup jane xxup seymour and xxup anthony xxup andrews give stiff , rather uncomfortable to watch performances in which the events move much too slowly to hold attention . \n",
       " \n",
       "  xxmaj it 's hard to understand why a star of xxup olivia xxup de xxup havilland 's caliber would wish to play the supporting role of xxmaj aunt xxmaj bessie since the role is so colorless she just about fades out of sight . xxmaj at this stage in her career , xxmaj olivia was appearing in so many \" nobility \" roles requiring a regal presence but nothing more . \n",
       " \n",
       "  a trivial movie best left forgotten among all the made - for - xxup tv movies of that era .,xxbos xxmaj deep xxmaj sea xxup 3d is a stunning insight in to an underwater world only a few have had the opportunity to view first hand . \n",
       " \n",
       "  xxmaj from the opening sequence when a wave rushes towards the audience momentarily engulfing us in the ocean , the filmmakers make full use of the xxup imax format . a jelly fish field appears to fill the whole theatre , a shark powers towards us , predators pounce from behind rocks and devour their prey . xxmaj it is a beautifully captured under sea feast for the eyes . \n",
       " \n",
       "  xxmaj our ears on the other hand , are not given the same treatment . xxmaj the film is narrated by xxmaj hollywood stars xxmaj jonny xxmaj depp and xxmaj kate xxmaj winslet . xxmaj both sound so ridiculous it positively spoils the enjoyment of the visuals . xxmaj depp sounds slightly bored whilst xxmaj winslet sounds as if she is reading a bedtime story to the village idiot . i was shocked that an actress of her status could have pitched her performance so wrongly . xxmaj the script is fairly silly and contains very little depth . xxmaj the soundtrack is filled with strange , unrealistic sound effects which i assume are meant to be funny but in fact detract attention from the material which should have been allowed to speak for itself . \n",
       " \n",
       "  xxmaj danny xxmaj elfman has provided an excellent score which gives plenty of impact to the ups and downs of life under the sea , when it is allowed to play out without the silly bubble sounds or xxunk xxunk which pepper film . \n",
       " \n",
       "  xxmaj the film is a technical marvel but with it 's childish script , annoying narration and misplaced sound effects it can not be taken seriously .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: /home/user/.fastai/data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fd1c054c680>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/user/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn.load('first');\n",
    "learn.load('first_edit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.143296</td>\n",
       "      <td>0.255684</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2) # 마지막 2개의 layer만 parameter updata의 대상이 된다. (그 앞의 layer들은 전부다 freeze)\n",
    "#learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.99,0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('second')\n",
    "learn.save('second_edit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load('second');\n",
    "learn.load('second_edit');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.127288</td>\n",
       "      <td>0.250797</td>\n",
       "      <td>0.908320</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3) # 이번엔 마지막 3개의 layer를 update 해보자. layer가 많이 업데이트될수록, 학습 연산량은 늘어나지만, (일반적으로) 성능은 좋아진다.\n",
    "#learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.99,0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('third')\n",
    "learn.save('third_edit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load('third');\n",
    "learn.load('third_edit');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * accuracy가 떨어지는 것을 확인하였다. 94% -> 91%. 기본 세팅되어있는 moms가 optimal 가까운 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.150544</td>\n",
       "      <td>0.245080</td>\n",
       "      <td>0.903880</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.121545</td>\n",
       "      <td>0.239538</td>\n",
       "      <td>0.910720</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "#learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.99,0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category pos, tensor(1), tensor([7.9091e-05, 9.9992e-01]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이전 결과\n",
    "learn.predict(\"I really loved that movie, it was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category pos, tensor(1), tensor([8.4620e-04, 9.9915e-01]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# momentum parameter 변경 후 결과\n",
    "learn.predict(\"I really loved that movie, it was awesome!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment:\n",
    "\n",
    "- IMDB는 NLP에서 가장 널리 사용되는 데이터셋인데, fastai에서 제공하는 NLP library를 사용하면 굉장히 쉽게 사용할 수 있어서 좋았다.\n",
    "- 하지만 vision과는 달리 NLP는 기본 모델 제공되는 것으로 높은 성능이 나오지는 않아서 사용하기 힘들다고 알려져 있는데, AWD-LSTM만으로 94% acc가 나오는것이 굉장히 신기했다.\n",
    "- 한국어의 경우엔 NSMC(Naver Sentiment Movie Corpus)가 있는데, 현재 공개된 코드중에 max가 92%로 알려져있다.\n",
    "- fastai 모델을 통해 NSMC를 사용해보는 것도 재밌을 것 같다. AWD-LSTM 말고도 Transformer들도 제공하기 때문에, 손쉽게 구현가능할 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
